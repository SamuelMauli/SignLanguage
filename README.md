# ğŸ¤– Reconhecimento do Alfabeto em ASL com MediaPipe e Scikit-learn

Este projeto utiliza visÃ£o computacional e machine learning para reconhecer, em tempo real, as letras do alfabeto da LÃ­ngua de Sinais Americana (ASL) utilizando webcam e anÃ¡lise de landmarks da mÃ£o.

> **Status:** ğŸš§ Em desenvolvimento â€“ prova de conceito inicial.

---

## ğŸ“Œ Ãndice

- [Sobre o Projeto](#sobre-o-projeto)
- [Fluxo de Funcionamento](#fluxo-de-funcionamento)
- [Tecnologias Utilizadas](#tecnologias-utilizadas)
- [Como Executar](#como-executar)
- [Estrutura de Pastas](#estrutura-de-pastas)
- [VÃ­deo Demonstrativo](#vÃ­deo-demonstrativo)
- [Melhorias Futuras](#melhorias-futuras)

---

## ğŸ¦¾ Sobre o Projeto

O objetivo Ã© desenvolver um sistema capaz de reconhecer as 26 letras do alfabeto em ASL a partir de imagens ou vÃ­deo em tempo real. Em vez de processar imagens brutas, a aplicaÃ§Ã£o utiliza landmarks (pontos de referÃªncia) da mÃ£o para tornar o modelo mais robusto em relaÃ§Ã£o Ã  iluminaÃ§Ã£o, fundo e tom de pele.

---

## âš™ï¸ Fluxo de Funcionamento

1. **ExtraÃ§Ã£o de CaracterÃ­sticas (MediaPipe Hands):**
   - SÃ£o utilizados os 21 pontos-chave (landmarks) da mÃ£o.
   - Os dados sÃ£o normalizados em relaÃ§Ã£o ao ponto do pulso (landmark 0) para eliminar variaÃ§Ãµes de posiÃ§Ã£o e escala.

2. **Treinamento com Random Forest:**
   - O modelo `RandomForestClassifier` da Scikit-learn Ã© utilizado pela sua precisÃ£o e robustez.

3. **ValidaÃ§Ã£o com K-Fold Estratificado:**
   - Utiliza validaÃ§Ã£o cruzada com 5 divisÃµes para garantir a generalizaÃ§Ã£o do modelo.

4. **AnÃ¡lise de Desempenho:**
   - GeraÃ§Ã£o de relatÃ³rio de classificaÃ§Ã£o (precision, recall, F1-score).
   - VisualizaÃ§Ã£o da matriz de confusÃ£o.

5. **Reconhecimento em Tempo Real:**
   - O modelo final Ã© salvo e usado para prever letras capturadas via webcam, com exibiÃ§Ã£o ao vivo da prediÃ§Ã£o.

---

## ğŸ› ï¸ Tecnologias Utilizadas

- **Python 3.8+**
- **OpenCV** â€“ Captura e manipulaÃ§Ã£o de vÃ­deo.
- **MediaPipe** â€“ ExtraÃ§Ã£o dos landmarks da mÃ£o.
- **Scikit-learn** â€“ Treinamento, validaÃ§Ã£o e mÃ©tricas.
- **NumPy** â€“ OperaÃ§Ãµes matriciais e normalizaÃ§Ã£o.
- **Matplotlib / Seaborn** â€“ VisualizaÃ§Ã£o grÃ¡fica.
- **tqdm** â€“ Feedback visual em loops demorados.

---

## ğŸš€ Como Executar

### 1. PrÃ©-requisitos

- Python 3.8+
- pip
- Webcam

### 2. Clonar o RepositÃ³rio

```bash
git clone https://github.com/SamuelMauli/SignLanguage.git
cd SignLanguage
```

### 3. Baixar o Dataset

- FaÃ§a o download do dataset ASL Alphabet:  
  ğŸ‘‰ [ASL Alphabet - Kaggle](https://www.kaggle.com/datasets/grassknoted/asl-alphabet)
- Extraia o conteÃºdo dentro da pasta `archive/`.

### 4. Criar Ambiente Virtual

```bash
python -m venv .venv
# Ativar no Linux/macOS
source .venv/bin/activate
# Ativar no Windows
.venv\Scripts\activate
```

### 5. Instalar DependÃªncias

```bash
pip install -r requirements.txt
```

> Exemplo do arquivo `requirements.txt`:

```txt
opencv-python
mediapipe
scikit-learn
numpy
matplotlib
seaborn
tqdm
```

### 6. Executar o Reconhecimento

```bash
python treinar_modelo.py
```

---

## ğŸ“ Estrutura de Pastas

```
SignLanguage/
â”œâ”€â”€ archive/
â”‚   â”œâ”€â”€ asl_alphabet_train/
â”‚   â”‚   â”œâ”€â”€ A/, B/, C/, ..., Z/
â”‚   â””â”€â”€ asl_alphabet_test/
â”‚       â”œâ”€â”€ A_test.jpg, ..., Z_test.jpg
â”œâ”€â”€ asl_class_labels.npy
â”œâ”€â”€ asl_random_forest_model.joblib
â”œâ”€â”€ treinar_modelo.py
â”œâ”€â”€ reconhecimento.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ¥ VÃ­deo Demonstrativo

Assista Ã  demonstraÃ§Ã£o do sistema em funcionamento:  
ğŸ‘‰ [Ver no Google Drive](https://drive.google.com/file/d/1D4EhIK6ydQQXVrySmS_nyaniHppaC8t4/view?usp=sharing)

---

## ğŸ”® Melhorias Futuras

- ğŸ“ˆ Testar outros modelos: `XGBoost`, `SVM`, `MLPClassifier`.
- ğŸ§  Reconhecimento de sinais dinÃ¢micos (ex.: frases) com LSTM/Transformer.
- â• Adicionar nÃºmeros e sÃ­mbolos ao vocabulÃ¡rio.
- ğŸ–¥ï¸ Criar uma interface grÃ¡fica com `Tkinter` ou `PyQt`.
- âš¡ Otimizar tempo de execuÃ§Ã£o para real-time mais fluido.